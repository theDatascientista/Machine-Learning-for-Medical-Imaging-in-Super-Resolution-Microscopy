{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model\n",
    "\n",
    "## Table of Contents\n",
    "1. [Model Choice](#model-choice)\n",
    "2. [Feature Selection](#feature-selection)\n",
    "3. [Implementation](#implementation)\n",
    "4. [Evaluation](#evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import skimage\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import ReLU, Conv2D, MaxPooling2D, UpSampling2D, Input, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check TF versions and CPU/GPU availability\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices())\n",
    "print(tf.test.is_gpu_available)\n",
    "print(tf.test.is_built_with_cuda())\n",
    "print(tf.test.is_built_with_gpu_support())\n",
    "print(\"Num CPUs Available: \", len(tf.config.list_physical_devices('CPU')))\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/content/drive/My Drive/Untrained-PINN-for-SIM-main\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2#show first picture of folder as image in notebook\n",
    "img = cv2.imread('Data/LPSIM/microtubules/input_frames/1_1.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Choice\n",
    "\n",
    "[Explain why you've chosen a particular model as the baseline. This could be a simple statistical model or a basic machine learning model. Justify your choice.]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "[Indicate which features from the dataset you will be using for the baseline model, and justify your selection.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Replace 'your_dataset.csv' with the path to your actual dataset\n",
    "df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Feature selection\n",
    "# Example: Selecting only two features for a simple baseline model\n",
    "X = df[['feature1', 'feature2']]\n",
    "y = df['target_variable']\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "[Implement your baseline model here.]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the baseline model\n",
    "# Example for a classification problem using Logistic Regression\n",
    "# model = LogisticRegression()\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# Your implementation code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "os.chdir('/content/drive/My Drive/Untrained-PINN-for-SIM-main')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import skimage\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import ReLU, Conv2D, MaxPooling2D, UpSampling2D, Input, concatenate\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global variables\n",
    "num_im = 50      # Number of examples in dataset\n",
    "frames = 24       # Number of sub-frames per example\n",
    "im_dim = 480     # Image dimension (after super-res)\n",
    "bg_lvl = 0       # Optional bg level subtraction\n",
    "k_size = 3\n",
    "learning_rate = 0.001 # Kept from the last successful training in the context.\n",
    "eps = 1000 # Kept from the last successful training in the context.\n",
    "BATCH_SIZE = 8 # Kept from the last successful training in the context.\n",
    "\n",
    "# Initialize empty NumPy arrays\n",
    "input_frames = np.zeros([num_im, im_dim, im_dim, frames], dtype=np.float32)\n",
    "gt_frames = np.zeros([num_im, im_dim, im_dim, 1], dtype=np.float32)\n",
    "lr_frames = np.zeros([num_im, im_dim, im_dim, 1], dtype=np.float32)\n",
    "patterns = np.zeros([frames, im_dim, im_dim, 1], dtype=np.float32)\n",
    "\n",
    "# Define data paths\n",
    "data_name = 'microtubules'\n",
    "dir_name = 'Data/LPSIM/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and resize input_frames, gt_frames, and lr_frames\n",
    "for i in range(1, num_im):\n",
    "    for j in range(1, (frames + 1)):\n",
    "        input_path = dir_name + data_name + '/input_frames/' + str(i) + '_' + str(j) + '.png'\n",
    "        input_temp = cv2.imread(input_path, 0)\n",
    "        if input_temp is None:\n",
    "            raise FileNotFoundError(f\"File not found: {input_path}\")\n",
    "        input_temp = cv2.resize(input_temp, dsize=(im_dim, im_dim), interpolation=cv2.INTER_CUBIC)\n",
    "        input_frames[i - 1, :, :, j - 1] = input_temp\n",
    "\n",
    "    gt_path = dir_name + data_name + '/ground_truth/' + str(i) + '.png'\n",
    "    gt_temp = cv2.imread(gt_path, 0)\n",
    "    if gt_temp is None:\n",
    "        raise FileNotFoundError(f\"File not found: {gt_path}\")\n",
    "    gt_temp = cv2.resize(gt_temp, dsize=(im_dim, im_dim), interpolation=cv2.INTER_CUBIC)\n",
    "    gt_frames[i - 1, :, :, :] = gt_temp.reshape([im_dim, im_dim, 1]) # Reshape to add channel dimension\n",
    "\n",
    "    lr_path = dir_name + data_name + '/low_res/' + str(i) + '.png'\n",
    "    lr_temp = cv2.imread(lr_path, 0)\n",
    "    if lr_temp is None:\n",
    "        raise FileNotFoundError(f\"File not found: {lr_path}\")\n",
    "    lr_temp = cv2.resize(lr_temp, dsize=(im_dim, im_dim), interpolation=cv2.INTER_CUBIC)\n",
    "    lr_frames[i - 1, :, :, :] = lr_temp.reshape([im_dim, im_dim, 1]) # Reshape to add channel dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and resize patterns\n",
    "for i in range(1, (frames + 1)):\n",
    "    pattern_path = dir_name + data_name + '/patterns/' + str(i) + '.png'\n",
    "    pattern_temp = cv2.imread(pattern_path, 0)\n",
    "    if pattern_temp is None:\n",
    "        raise FileNotFoundError(f\"File not found: {pattern_path}\")\n",
    "    pattern = cv2.resize(pattern_temp, dsize=(im_dim, im_dim), interpolation=cv2.INTER_CUBIC)\n",
    "    patterns[i - 1, :, :, :] = pattern.reshape([im_dim, im_dim, 1]) # Reshape to add channel dimension\n",
    "\n",
    "# Normalize all loaded data arrays\n",
    "input_frames = input_frames - bg_lvl\n",
    "input_frames[input_frames < 0] = 0\n",
    "if np.amax(input_frames) > 0: # Avoid division by zero\n",
    "    input_frames = input_frames / np.amax(input_frames)\n",
    "\n",
    "if np.amax(gt_frames) > 0:\n",
    "    gt_frames = gt_frames / np.amax(gt_frames)\n",
    "\n",
    "if np.amax(lr_frames) > 0:\n",
    "    lr_frames = lr_frames / np.amax(lr_frames)\n",
    "\n",
    "if np.amax(patterns) > 0:\n",
    "    patterns = patterns / np.amax(patterns)\n",
    "\n",
    "# Load and reshape PSF\n",
    "psf_path = dir_name + data_name + '/psf.png'\n",
    "psf = cv2.imread(psf_path, 0)\n",
    "if psf is None:\n",
    "    raise FileNotFoundError(f\"File not found: {psf_path}\")\n",
    "if np.amax(psf) > 0: # Normalize PSF if max value is greater than zero\n",
    "    psf = psf / np.amax(psf)\n",
    "psf = np.reshape(psf, [np.ma.size(psf, 0), np.ma.size(psf, 0), 1, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define flexible U-Net architecture function\n",
    "def u_net_flexible(input_channels):\n",
    "\n",
    "    inputs = Input((im_dim, im_dim, input_channels))\n",
    "    block1 = Conv2D(32, (k_size, k_size), padding=\"same\", activation = 'relu')(inputs)\n",
    "    block2 = Conv2D(32, (k_size, k_size), padding=\"same\", activation = 'relu')(block1)\n",
    "    block2 = Conv2D(32, (k_size, k_size), padding=\"same\", activation = 'relu')(block2)\n",
    "    down1 = MaxPooling2D(pool_size=(2,2))(block2)\n",
    "    block3 = Conv2D(64, (k_size, k_size), padding=\"same\", activation = 'relu')(down1)\n",
    "    block3 = Conv2D(64, (k_size, k_size), padding=\"same\", activation = 'relu')(block3)\n",
    "    down2 = MaxPooling2D(pool_size=(2,2))(block3)\n",
    "    block4 = Conv2D(128, (k_size, k_size), padding=\"same\", activation = 'relu')(down2)\n",
    "    block4 = Conv2D(128, (k_size, k_size), padding=\"same\", activation = 'relu')(block4)\n",
    "    down3 = MaxPooling2D(pool_size=(2,2))(block4)\n",
    "    block5 = Conv2D(256, (k_size, k_size), padding=\"same\", activation = 'relu')(down3)\n",
    "    block5 = Conv2D(256, (k_size, k_size), padding=\"same\", activation = 'relu')(block5)\n",
    "    up1 = UpSampling2D(size=(2,2))(block5)\n",
    "    cat1 = concatenate([block4,up1])\n",
    "    block6 = Conv2D(128, (k_size, k_size), padding=\"same\", activation = 'relu')(cat1)\n",
    "    block6 = Conv2D(128, (k_size, k_size), padding=\"same\", activation = 'relu')(block6)\n",
    "    up2 = UpSampling2D(size=(2,2))(block6)\n",
    "    cat2 = concatenate([block3,up2])\n",
    "    block7 = Conv2D(64, (k_size, k_size), padding=\"same\", activation = 'relu')(cat2)\n",
    "    block7 = Conv2D(64, (k_size, k_size), padding=\"same\", activation = 'relu')(block7)\n",
    "    up3 = UpSampling2D(size=(2,2))(block7)\n",
    "    cat3 = concatenate([block2,up3])\n",
    "    block8 = Conv2D(32, (k_size, k_size), padding=\"same\", activation = 'relu')(cat3)\n",
    "    block8 = Conv2D(32, (k_size, k_size), padding=\"same\", activation = 'relu')(block8)\n",
    "    block9 = Conv2D(32, (k_size, k_size), padding=\"same\", activation = 'relu')(block8)\n",
    "    output = Conv2D(1, (1, 1), padding=\"same\")(block9)\n",
    "    output = tf.keras.layers.ReLU(max_value=1.0)(output)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[output])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define loss and learning rate schedule\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    learning_rate,\n",
    "    decay_steps=50,\n",
    "    decay_rate=0.90,\n",
    "    staircase=True)\n",
    "\n",
    "mse_loss = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation for batch training and augmentation\n",
    "# Select a range of indices for the batch\n",
    "start_idx = 0\n",
    "if start_idx + BATCH_SIZE > num_im:\n",
    "    start_idx = num_im - BATCH_SIZE\n",
    "\n",
    "# Create empty lists to store augmented data\n",
    "x_batch_augmented = []\n",
    "y_batch_augmented = []\n",
    "\n",
    "# Define data augmentation function\n",
    "def augment_data_pair(lr_img, gt_img):\n",
    "    # Random horizontal flip\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        lr_img = tf.image.flip_left_right(lr_img)\n",
    "        gt_img = tf.image.flip_left_right(gt_img)\n",
    "\n",
    "    # Random vertical flip\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        lr_img = tf.image.flip_up_down(lr_img)\n",
    "        gt_img = tf.image.flip_up_down(gt_img)\n",
    "\n",
    "    # Random 90-degree rotation\n",
    "    k = tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)\n",
    "    lr_img = tf.image.rot90(lr_img, k=k)\n",
    "    gt_img = tf.image.rot90(gt_img, k=k)\n",
    "\n",
    "    return lr_img, gt_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the selected range of images and apply augmentation\n",
    "for i in range(start_idx, start_idx + BATCH_SIZE):\n",
    "    # Convert NumPy arrays to TensorFlow tensors\n",
    "    current_lr = tf.convert_to_tensor(lr_frames[i, :, :, :], dtype=tf.float32)\n",
    "    current_gt = tf.convert_to_tensor(gt_frames[i, :, :, :], dtype=tf.float32)\n",
    "\n",
    "    # Apply augmentation\n",
    "    augmented_lr, augmented_gt = augment_data_pair(current_lr, current_gt)\n",
    "\n",
    "    # Convert augmented TensorFlow tensors back to NumPy and append\n",
    "    x_batch_augmented.append(augmented_lr.numpy())\n",
    "    y_batch_augmented.append(augmented_gt.numpy())\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "x_batch_augmented = np.array(x_batch_augmented)\n",
    "y_batch_augmented = np.array(y_batch_augmented)\n",
    "\n",
    "# Ensure final shapes\n",
    "x_batch_augmented = x_batch_augmented.reshape((BATCH_SIZE, im_dim, im_dim, 1))\n",
    "y_batch_augmented = y_batch_augmented.reshape((BATCH_SIZE, im_dim, im_dim, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define baseline_model function\n",
    "def baseline_model():\n",
    "    inputs = Input(shape=(im_dim, im_dim, 1))\n",
    "    x = Conv2D(32, (k_size, k_size), activation='relu', padding='same')(inputs)\n",
    "    x = Conv2D(64, (k_size, k_size), activation='relu', padding='same')(x)\n",
    "    x = Conv2D(64, (k_size, k_size), activation='relu', padding='same')(x)\n",
    "    x = Conv2D(32, (k_size, k_size), activation='relu', padding='same')(x)\n",
    "    outputs = Conv2D(1, (k_size, k_size), activation='relu', padding='same')(x)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Re-instantiate the baseline model\n",
    "baseline_cnn_model = baseline_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Fehler bei baseline model ...batch training verwechslung\n",
    "\n",
    "\n",
    "\n",
    "# Recompile and re-train the baseline model to ensure it's ready for prediction\n",
    "opt_baseline = tf.keras.optimizers.Adam(lr_schedule)\n",
    "baseline_cnn_model.compile(loss=mse_loss, optimizer=opt_baseline)\n",
    "\n",
    "baseline_model_history = baseline_cnn_model.fit(\n",
    "\n",
    "predicted_baseline = baseline_cnn_model.predict(\n",
    "\n",
    "# Select the first image from the batch for visualization\n",
    "idx_to_visualize = 0\n",
    "\n",
    "# Prepare predicted image\n",
    "predicted_baseline_viz = predicted_baseline[idx_to_visualize, :, :, :].reshape([im_dim, im_dim])\n",
    "predicted_baseline_viz = predicted_baseline_viz[20:(im_dim-20), 20:(im_dim-20)] # Crop\n",
    "predicted_baseline_viz = (predicted_baseline_viz - np.amin(predicted_baseline_viz)) / (np.amax(predicted_baseline_viz) - np.amin(predicted_baseline_viz)) # Normalize\n",
    "\n",
    "# Prepare ground truth image (from y_batch_augmented)\n",
    "gt_baseline_viz = y_batch_augmented[idx_to_visualize, :, :, :].reshape([im_dim, im_dim])\n",
    "gt_baseline_viz = gt_baseline_viz[20:(im_dim-20), 20:(im_dim-20)] # Crop\n",
    "gt_baseline_viz = (gt_baseline_viz - np.amin(gt_baseline_viz)) / (np.amax(gt_baseline_viz) - np.amin(gt_baseline_viz)) # Normalize\n",
    "\n",
    "# Prepare low-resolution input image (from x_batch_augmented)\n",
    "lr_baseline_viz = x_batch_augmented[idx_to_visualize, :, :, :].reshape([im_dim, im_dim])\n",
    "lr_baseline_viz = lr_baseline_viz[20:(im_dim-20), 20:(im_dim-20)] # Crop\n",
    "lr_baseline_viz = (lr_baseline_viz - np.amin(lr_baseline_viz)) / (np.amax(lr_baseline_viz) - np.amin(lr_baseline_viz)) # Normalize\n",
    "\n",
    "# Display images\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(gt_baseline_viz, cmap='inferno')\n",
    "plt.title('Ground Truth Image')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(predicted_baseline_viz, cmap='inferno')\n",
    "plt.title('Baseline CNN Result')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(lr_baseline_viz, cmap='inferno')\n",
    "plt.title('Low Resolution Input')\n",
    "plt.show()\n",
    "\n",
    "# Calculate PSNR and SSIM for the baseline model\n",
    "\n",
    "psnr_baseline = peak_signal_noise_ratio(gt_baseline_viz, predicted_baseline_viz, data_range=1.0)\n",
    "ssim_baseline = structural_similarity(gt_baseline_viz, predicted_baseline_viz, data_range=1.0)\n",
    "\n",
    "print(f\"Baseline CNN Model - PSNR: {psnr_baseline:.4f}\")\n",
    "print(f\"Baseline CNN Model - SSIM: {ssim_baseline:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "[Clearly state what metrics you will use to evaluate the model's performance. These metrics will serve as a starting point for evaluating more complex models later on.]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the baseline model\n",
    "# Example for a classification problem\n",
    "# y_pred = model.predict(X_test)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# For a regression problem, you might use:\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Your evaluation code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
