{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model\n",
    "\n",
    "## Table of Contents\n",
    "1. [Model Choice](#model-choice)\n",
    "2. [Feature Selection](#feature-selection)\n",
    "3. [Implementation](#implementation)\n",
    "4. [Evaluation](#evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import skimage\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import ReLU, Conv2D, MaxPooling2D, UpSampling2D, Input, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check TF versions and CPU/GPU availability\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices())\n",
    "print(tf.test.is_gpu_available)\n",
    "print(tf.test.is_built_with_cuda())\n",
    "print(tf.test.is_built_with_gpu_support())\n",
    "print(\"Num CPUs Available: \", len(tf.config.list_physical_devices('CPU')))\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/content/drive/My Drive/Untrained-PINN-for-SIM-main\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 #show first picture of folder as image in notebook\n",
    "img = cv2.imread('Data/LPSIM/microtubules/input_frames/1_1.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Choice\n",
    "\n",
    "The first baseline CNN model was optimized and split into train and validation  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "num_im = 50      # Number of examples in dataset\n",
    "frames = 24       # Number of sub-frames per example\n",
    "im_dim = 480     # Image dimension (after super-res)\n",
    "bg_lvl = 0       # Optional bg level subtraction\n",
    "\n",
    "input_frames = np.zeros([num_im,im_dim,im_dim,frames])\n",
    "gt_frames = np.zeros([num_im,im_dim,im_dim,1])\n",
    "lr_frames = np.zeros([num_im,im_dim,im_dim,1])\n",
    "patterns = np.zeros([frames,im_dim,im_dim,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'microtubules'\n",
    "dir_name = 'Data/LPSIM/'\n",
    "\n",
    "for i in range(1,num_im):\n",
    "      \n",
    "    for j in range(1,(frames+1)):\n",
    "       \n",
    "        input_path = dir_name+data_name+'/input_frames/'+str(i)+'_'+str(j)+'.png'\n",
    "        input_temp = cv2.imread(input_path,0)\n",
    "        input_temp = cv2.resize(input_temp,dsize=(im_dim,im_dim), interpolation=cv2.INTER_CUBIC)\n",
    "        input_frames[i-1,:,:,j-1] = input_temp                  \n",
    "    \n",
    "    gt_path = dir_name+data_name+'/ground_truth/'+str(i)+'.png'\n",
    "    gt_temp = cv2.imread(gt_path,0)\n",
    "    gt_temp = cv2.resize(gt_temp,dsize=(im_dim,im_dim), interpolation=cv2.INTER_CUBIC)\n",
    "    gt_temp = gt_temp.reshape([im_dim,im_dim,1])\n",
    "    gt_frames[i-1,:,:,:] = gt_temp\n",
    "\n",
    "    lr_path = dir_name+data_name+'/low_res/'+str(i)+'.png'\n",
    "    lr_temp = cv2.imread(lr_path,0)\n",
    "    lr_temp = cv2.resize(lr_temp,dsize=(im_dim,im_dim), interpolation=cv2.INTER_CUBIC)\n",
    "    lr_temp = lr_temp.reshape([im_dim,im_dim,1])\n",
    "    lr_frames[i-1,:,:,:] = lr_temp\n",
    "    \n",
    "\n",
    "for i in range(1,(frames+1)):\n",
    "    \n",
    "    pattern_path = dir_name+data_name+'/patterns/'+str(i)+'.png'\n",
    "    pattern_temp = cv2.imread(pattern_path,0)\n",
    "    pattern = cv2.resize(pattern_temp,dsize=(im_dim,im_dim), interpolation=cv2.INTER_CUBIC)  \n",
    "    pattern = pattern.reshape([im_dim,im_dim,1])\n",
    "    patterns[i-1,:,:,:] = pattern\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check and Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.amax(input_frames))\n",
    "input_frames = input_frames - bg_lvl;\n",
    "input_frames[input_frames<0] = 0\n",
    "input_frames = input_frames/np.amax(input_frames)\n",
    "print(np.amax(input_frames))\n",
    "gt_fames = gt_frames/np.amax(gt_frames)\n",
    "lr_frames = lr_frames/np.amax(lr_frames)\n",
    "patterns = patterns/np.amax(patterns)\n",
    "print(input_frames.shape)\n",
    "print(gt_frames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(input_frames[1,:,:,1])\n",
    "plt.title('Single input frame')\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(gt_frames[1,:,:,:])\n",
    "plt.title('Ground truth image')\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(lr_frames[1,:,:,:])\n",
    "plt.title('Low resolution image')\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(patterns[1,:,:,:])\n",
    "plt.title('Illumination pattern')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define PSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf = cv2.imread(dir_name+data_name+'/psf.png',0)\n",
    "plt.imshow(psf)\n",
    "psf = np.reshape(psf,[np.ma.size(psf,0),np.ma.size(psf,0),1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_baseline, y_baseline, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Shape of x_train: {x_train.shape}\")\n",
    "print(f\"Shape of x_val: {x_val.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of y_val: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement callback \n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Create an EarlyStopping callback instance\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,  # Number of epochs with no improvement after which training will be stopped.\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "print(\"EarlyStopping callback defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "def baseline_model_with_dropout():\n",
    "    # Input layer with shape (im_dim, im_dim, 1) for low-resolution images\n",
    "    inputs = Input(shape=(im_dim, im_dim, 1))\n",
    "\n",
    "    # Encoder part / feature extraction layers\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = Dropout(0.25)(x) # Added Dropout\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = Dropout(0.25)(x) # Added Dropout\n",
    "\n",
    "    # Decoder part / reconstruction layers\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = Dropout(0.25)(x) # Added Dropout\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = Dropout(0.25)(x) # Added Dropout\n",
    "\n",
    "    # Output layer: 1 filter for a single channel output image\n",
    "    outputs = Conv2D(1, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Instantiate the baseline model with dropout\n",
    "baseline_cnn_model = baseline_model_with_dropout()\n",
    "\n",
    "# Print the model summary\n",
    "print(\"Baseline CNN Model with Dropout Architecture:\")\n",
    "baseline_cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_learning_rate = 0.001 \n",
    "\n",
    "# Define the new loss function and optimizer\n",
    "\n",
    "new_lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    new_learning_rate,\n",
    "    decay_steps=100, # Adjusted decay steps\n",
    "    decay_rate=0.95, # Adjusted decay rate for slower decay\n",
    "    staircase=True)\n",
    "\n",
    "opt_baseline_tuned = tf.keras.optimizers.Adam(new_lr_schedule)\n",
    "\n",
    "# Compile the baseline model with the new optimizer\n",
    "baseline_cnn_model.compile(loss=mse_loss, optimizer=opt_baseline_tuned)\n",
    "\n",
    "print(\"Baseline CNN model recompiled with tuned learning rate schedule.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting baseline CNN model training with optimizations...\")\n",
    "\n",
    "baseline_model_history_optimized = baseline_cnn_model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=eps, # Use the previously defined number of epochs\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[early_stopping_callback], # Add the EarlyStopping callback\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(\"Baseline CNN model training with optimizations finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Plot loss curves\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(np.linspace(1, len(baseline_model_history_optimized.history['loss']), num=len(baseline_model_history_optimized.history['loss'])), baseline_model_history_optimized.history['loss'], label='Training Loss')\n",
    "plt.plot(np.linspace(1, len(baseline_model_history_optimized.history['val_loss']), num=len(baseline_model_history_optimized.history['val_loss'])), baseline_model_history_optimized.history['val_loss'], label='Validation Loss')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Optimized Baseline Model Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "A visual comparison of the original and ground truth images with the predicted images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluatiuon of predicted images of baseline model\n",
    "\n",
    "num_examples_to_show = 3 # Number of examples to visualize\n",
    "\n",
    "# Generate predictions on the validation set\n",
    "predictions = baseline_cnn_model.predict(x_val)\n",
    "\n",
    "# Visualize predictions for a few examples\n",
    "plt.figure(figsize=(num_examples_to_show * 4, 12))\n",
    "for i in range(num_examples_to_show):\n",
    "    # Original Low-Resolution Input\n",
    "    plt.subplot(3, num_examples_to_show, i + 1)\n",
    "    plt.imshow(x_val[i, :, :, 0], cmap='inferno')\n",
    "    plt.title(f'Val Input {i+1}')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Ground Truth\n",
    "    plt.subplot(3, num_examples_to_show, i + 1 + num_examples_to_show)\n",
    "    plt.imshow(y_val[i, :, :, 0], cmap='inferno')\n",
    "    plt.title(f'Ground Truth {i+1}')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Model Prediction\n",
    "    plt.subplot(3, num_examples_to_show, i + 1 + 2 * num_examples_to_show)\n",
    "    plt.imshow(predictions[i, :, :, 0], cmap='inferno')\n",
    "    plt.title(f'Prediction {i+1}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.suptitle('Comparison of Low-Res Input, Ground Truth, and Model Predictions on Validation Set')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to prevent suptitle overlap\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
